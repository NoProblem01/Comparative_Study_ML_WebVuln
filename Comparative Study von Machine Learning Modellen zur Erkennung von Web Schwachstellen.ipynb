{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41cdae0",
   "metadata": {},
   "source": [
    "# Code zu der Bachelorarbeit:\n",
    "# \"Comparitve Study von Machine Learning Modellen zur Erkennung von Web Schwachstellen\"\n",
    "## von Nils Pudenz, 2735230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512b38",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dac7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install kaggle scikit-learn xgboost catboost tabpfn pandas numpy matplotlib seaborn -q\n",
    "#%pip install --quiet scikit-learn xgboost catboost tabpfn chardet\n",
    "#%pip install -U scikit-learn\n",
    "## in deiner (Conda/venv) Umgebung\n",
    "#%pip install --upgrade \"torch==2.*\" --index-url https://download.pytorch.org/whl/cu121\n",
    "#%pip install --upgrade xgboost catboost scikit-learn pandas scipy tabpfn\n",
    "##wenn es komplikationen mit torch gibt, deiinstallieren und neu installieren\n",
    "#%pip uninstall torch\n",
    "#%pip install torch --index-url https://download.pytorch.org/whl/cu121 --upgrade\n",
    "#%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe89a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915add7c",
   "metadata": {},
   "source": [
    "## Check ob GPU verwendet werden kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5103769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "CUDA verfügbar: True\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(\"CUDA verfügbar:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b9e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Scripts\\python.exe\n",
      "Torch: 2.5.1+cu121 | CUDA build: 12.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\", sys.executable)\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fea7e",
   "metadata": {},
   "source": [
    "## mögliche Modeloptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47f16504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxgb = XGBClassifier(\\n    tree_method=\"hist\",        # CPU-Optimierung\\n    n_estimators=400,\\n    max_depth=6,\\n    learning_rate=0.1,\\n    subsample=0.9,\\n    colsample_bytree=0.8,\\n    n_jobs=-1,\\n    random_state=42\\n)\\n\\nfrom catboost import CatBoostClassifier\\ncat = CatBoostClassifier(\\n    iterations=400,\\n    depth=8,\\n    learning_rate=0.1,\\n    random_seed=42,\\n    loss_function=\"Logloss\",\\n    task_type=\"CPU\",\\n    thread_count=8,\\n    od_type=\"Iter\",            # early stopping\\n    od_wait=30,\\n    verbose=False\\n)\\n#'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xgb = XGBClassifier(\n",
    "    tree_method=\"hist\",        # CPU-Optimierung\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=400,\n",
    "    depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=42,\n",
    "    loss_function=\"Logloss\",\n",
    "    task_type=\"CPU\",\n",
    "    thread_count=8,\n",
    "    od_type=\"Iter\",            # early stopping\n",
    "    od_wait=30,\n",
    "    verbose=False\n",
    ")\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407c50e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvec = TfidfVectorizer(\\n    ngram_range=(3,5),\\n    max_features=50_000,\\n    sublinear_tf=True,\\n    lowercase=False\\n).fit(X_train_raw)           # nur einmal fitten\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speicher optimieren\n",
    "'''\n",
    "vec = TfidfVectorizer(\n",
    "    ngram_range=(3,5),\n",
    "    max_features=50_000,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=False\n",
    ").fit(X_train_raw)           # nur einmal fitten\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb31025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsearch_space = {\\n    \"max_depth\": [4, 6, 8],\\n    \"learning_rate\": [0.05, 0.1, 0.2],\\n    \"n_estimators\": [200, 400, 600]\\n}\\nrandcv = RandomizedSearchCV(\\n    xgb,\\n    search_space,\\n    n_iter=10,            # statt 3×3×3 = 27\\n    scoring=\"f1\",\\n    cv=3,\\n    n_jobs=-1\\n)\\nrandcv.fit(X_train_vec, y_train)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kleine Hyperparamsuche statt Grid-Overkill\n",
    "'''\n",
    "search_space = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [200, 400, 600]\n",
    "}\n",
    "randcv = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    search_space,\n",
    "    n_iter=10,            # statt 3×3×3 = 27\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "randcv.fit(X_train_vec, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ba5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\nilsp\\AppData\\Local\\Temp\\ipykernel_34512\\134699850.py\", line 3, in <module>\n",
      "    X_train_vec = vec.transform(X_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2128, in transform\n",
      "    X = super().transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1421, in transform\n",
      "    _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line None, in _count_vocab\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 773, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 536, in format_record\n",
      "    assert isinstance(frame_info.lineno, int)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(model, X, batch_size=512): #um Überlastung zu vermeiden, evtl. 256 oder 128\n",
    "    \"\"\"Make predictions on input data in batches.\"\"\"\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        batch = X[i:i + batch_size]\n",
    "        preds.append(model.predict(batch))\n",
    "    return np.concatenate(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350a6b7",
   "metadata": {},
   "source": [
    "## Dowload Kaggle Datasets\n",
    "Requires Kaggle API credentials ('~/.kaggle/kaggle.json') für API-Token, um zugriff auf die Datenbanken über das Kaggle Konto zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749404d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f5a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dowload der Datasets von Kaggle, Output =1 erfoglgreich, Output = 0 fehlerhaft\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/sql-injection-dataset -p data --unzip --quiet\")\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning -p data --unzip --quiet\")\n",
    "#KAGGLE_DATASETS = { #gleich wie oben nur renaming auf sql & xss\n",
    "#    \"sql\": \"syedsaqlainhussain/sql-injection-dataset\",\n",
    "#    \"xss\": \"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/syedsaqlainhussain/sql-injection-dataset\n",
      "Downloaded syedsaqlainhussain/sql-injection-dataset\n",
      "Dataset URL: https://www.kaggle.com/datasets/syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\n",
      "Downloaded syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\n"
     ]
    }
   ],
   "source": [
    "def kaggle_download(dataset, path=\"data\", unzip=True):\n",
    "    api = KaggleApi()\n",
    "    api.authenticate() #nutzt ~/.kaggle/kaggle.json für Authentifizierung oder Environment-Variablen\n",
    "    api.dataset_download_files(dataset, path=path, unzip=unzip)\n",
    "    print(f\"Downloaded {dataset}\")\n",
    "\n",
    "kaggle_download(\"syedsaqlainhussain/sql-injection-dataset\")#, path=DATA_DIR, unzip=True)\n",
    "kaggle_download(\"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\")#, path=DATA_DIR, unzip=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalten ansehen\n",
    "print(sql_df.columns.tolist())\n",
    "\n",
    "# Typische Index-/Hilfsspalten loswerden\n",
    "sql_df = sql_df.loc[:, ~sql_df.columns.str.contains(r\"^Unnamed|^index$\", case=False)]\n",
    "\n",
    "# Auf die Kernspalten reduzieren (falls etwas anderes drin ist)\n",
    "sql_df = sql_df[[\"Sentence\", \"Label\"]].copy()\n",
    "\n",
    "# Optional: Duplikate auf Satzebene entfernen (falls noch nicht passiert)\n",
    "sql_df = sql_df.drop_duplicates(subset=[\"Sentence\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"clean shape:\", sql_df.shape)  # Erwartung: (30873, 2)\n",
    "print(sql_df[\"Label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a79aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, df in {\"SQL\": sql_df, \"XSS\": xss_df}.items():\n",
    "    print(f\"{name} dataset shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "    display(df.describe())\n",
    "    display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d30aa",
   "metadata": {},
   "source": [
    "## Basic Cleaning\n",
    "* Drop Duplicate rows\n",
    "* Handle missing values (simple fill-na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce598302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (sql_df, xss_df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5eedf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xy(df: pd.DataFrame,\n",
    "                  label_candidates=(\"label\", \"class\", \"target\"),\n",
    "                  label_map=None):\n",
    "    if label_map is None:\n",
    "        label_map = {\n",
    "            \"0\": \"0\", \"1\": \"1\",\n",
    "            \"benign\": \"0\", \"normal\": \"0\", \"legitimate\": \"0\", \"safe\": \"0\",\n",
    "            \"attack\": \"1\", \"malicious\": \"1\", \"sql injection\": \"1\",\n",
    "            \"sql-injection\": \"1\", \"xss\": \"1\"\n",
    "        }\n",
    "\n",
    "    # Zielspalte finden (im *übergebenen* df!)\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    target_col = next((cols_lower[c] for c in label_candidates if c in cols_lower), None)\n",
    "    if target_col is None:\n",
    "        raise ValueError(f\"Keine Label-Spalte gefunden. Kandidaten: {label_candidates}\")\n",
    "\n",
    "    # Labels normieren -> nur 0/1 behalten\n",
    "    y_str = df[target_col].astype(str).str.strip().str.lower()\n",
    "    y_map = y_str.map(label_map)\n",
    "    mask = y_map.notna()\n",
    "    y = pd.to_numeric(y_map[mask]).astype(int).to_numpy()\n",
    "\n",
    "    # Rohtext aus allen Nicht-Label-Spalten zusammenbauen\n",
    "    feat_cols = [c for c in df.columns if c != target_col]\n",
    "    X_raw = df.loc[mask, feat_cols].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    return X_raw, y, target_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ce09f",
   "metadata": {},
   "source": [
    "# Globale Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Deterministische Ausgabe generieren, um die Reproduzierbarkeit zu gewährleisten\n",
    "RANDOM_STATE = 42\n",
    "#np.random.seed(RANDOM_STATE) wofür das?\n",
    "#random.seed(RANDOM_STATE)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()  # für TabPFN & XGBoost\n",
    "print(f\"[ENV] CUDA avail: {USE_CUDA} | Torch CUDA build: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6d9eb",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bf05a",
   "metadata": {},
   "source": [
    "## Evaluationsmetriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba189305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_metrics(y_true, y_pred) -> dict:\n",
    "    \"\"\"Präzision/Recall/F1 & Raten (FPR/FNR) für binäre Klassifikation.\"\"\"\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    p  = precision_score(y_true, y_pred)\n",
    "    r  = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = float(fp / (fp + tn)) if (fp + tn) else 0.0\n",
    "    fnr = float(fn / (fn + tp)) if (fn + tp) else 0.0\n",
    "    return dict(Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, name, use_batches=False, batch_size=256) -> dict: #Dictionary für Evaluierungsmetriken\n",
    "    \"\"\"Zeitmessung + Vorhersage (optional in Batches) + Metriken.\"\"\"\n",
    "    print(f\"→ Evaluate {name} on X_test={getattr(X_test,'shape',None)}\")\n",
    "    t0 = time.perf_counter()\n",
    "    if use_batches:\n",
    "        y_pred = predict_in_batches(model, X_test, batch_size=batch_size, verbose=True)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    pred_s = time.perf_counter() - t0\n",
    "    m = binary_metrics(y_test, y_pred)\n",
    "    res = dict(Model=name, Pred_s=pred_s, **m)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c572f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10bd60",
   "metadata": {},
   "source": [
    "### Batchweise Vorhersage für TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(model, X, batch_size=256, verbose=False):\n",
    "    \"\"\"Vorhersage in Batches (schont RAM/VRAM; wichtig für TabPFN).\"\"\"\n",
    "    n = X.shape[0]\n",
    "    out = []\n",
    "    total = math.ceil(n / batch_size)\n",
    "    for b, i in enumerate(range(0, n, batch_size), start=1):\n",
    "        j = min(i + batch_size, n)\n",
    "        t1 = time.perf_counter()\n",
    "        with torch.inference_mode():\n",
    "            out.append(model.predict(X[i:j]))\n",
    "        dt = time.perf_counter() - t1\n",
    "        if verbose:\n",
    "            print(f\"   [predict] batch {b:>3}/{total} ({j-i} rows) in {dt:.2f}s\")\n",
    "        if USE_CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "    return np.concatenate(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e87bd",
   "metadata": {},
   "source": [
    "### Label bereinigung der Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(df, label_col=\"Label\", text_cols=(\"Sentence\",)):\n",
    "    \"\"\"Bringt Labels robust auf {0,1} und gibt (X_raw, y) zurück.\"\"\"\n",
    "    df = df.copy()\n",
    "    y_raw = df[label_col].astype(str).str.strip().str.lower()\n",
    "    map01 = {\"0\": \"0\", \"1\": \"1\", \"benign\": \"0\", \"normal\": \"0\", \"legitimate\": \"0\", \"safe\": \"0\",\n",
    "             \"attack\": \"1\", \"malicious\": \"1\", \"sql injection\": \"1\", \"sql-injection\": \"1\", \"xss\": \"1\"}\n",
    "    y_map = y_raw.map(map01)\n",
    "    mask = y_map.notna()\n",
    "    y = pd.to_numeric(y_map[mask]).astype(int).to_numpy()\n",
    "    feat_cols = [c for c in df.columns if c != label_col]\n",
    "    X_raw = df.loc[mask, feat_cols].astype(str).agg(\" \".join, axis=1)\n",
    "    return X_raw, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7b6ec",
   "metadata": {},
   "source": [
    "# Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18928fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(256,128), activation=\"relu\",\n",
    "                         early_stopping=True, n_iter_no_change=5, max_iter=200,\n",
    "                         random_state=RANDOM_STATE),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.1,\n",
    "        subsample=0.9, colsample_bytree=0.8,\n",
    "        tree_method=\"hist\", device=(\"cuda\" if USE_CUDA else \"cpu\"),\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        iterations=400, depth=8, learning_rate=0.1,\n",
    "        loss_function=\"Logloss\", random_seed=RANDOM_STATE, verbose=False,\n",
    "        task_type=\"CPU\"   # stabil über Pool + Sparse; bei GPU: task_type=\"GPU\" und ggf. Dense verwenden\n",
    "    ),\n",
    "    \"TabPFN\": TabPFNClassifier(\n",
    "        device=(\"cuda\" if USE_CUDA else \"cpu\"),\n",
    "        ignore_pretraining_limits=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690192f4",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_ARGS = dict(ngram_range=(3,5), max_features=50_000, sublinear_tf=True, lowercase=False)\n",
    "\n",
    "TABPFN_MAX_SAMPLES = 4000     # starte konservativ; später 6000/8000 testen\n",
    "TABPFN_N_COMPONENTS = 150     # <=500, kleiner = schneller/ram-sparender\n",
    "TABPFN_BATCH = 128            # Batch für Predict; 128/64 bei RAM-Engpässen\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c27db",
   "metadata": {},
   "source": [
    "## Pipeline je Datensatz (TF-IDF; TabPFN: SVD + batched predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df, ds_name in [(sql_df, \"SQL\"), (xss_df, \"XSS\")]:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"DATASET: {ds_name}\")\n",
    "\n",
    "    # Labels/Text\n",
    "    X_raw, y = clean_labels(df, label_col=\"Label\", text_cols=(\"Sentence\",))\n",
    "    print(f\"[DATA] rows={len(y)} | pos={int(y.sum())} | neg={len(y)-int(y.sum())}\")\n",
    "\n",
    "    # Split \n",
    "    # Erst den Datensatz splitten, um Data Leakage vorzubeugen, Wujek et al. (2016)\n",
    "    X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    \n",
    "    # #Gemeinsmaer TF-IDF-Vectorizer (fit nur auf Train, wegen Oversampling)\n",
    "    vec = TfidfVectorizer(**VEC_ARGS)\n",
    "    t0 = time.perf_counter()\n",
    "    X_train_vec = vec.fit_transform(X_train_txt)\n",
    "    X_test_vec  = vec.transform(X_test_txt)\n",
    "    print(f\"[VEC] TF-IDF train={X_train_vec.shape}, test={X_test_vec.shape} in {time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "    # Modelle trainieren/evaluieren\n",
    "    for name, model in models.items():\n",
    "        print(\"-\"*50 + f\"\\nMODEL: {name} on {ds_name}\")\n",
    "\n",
    "        if name == \"CatBoost\":\n",
    "            # CatBoost stabil via Pool (sparse)\n",
    "            pool_train = Pool(X_train_vec, y_train)\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(pool_train)\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s\")\n",
    "            res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "            results.append(res)\n",
    "            print(res)\n",
    "\n",
    "        elif name == \"TabPFN\":\n",
    "            # ggf. Trainingsmenge stratifiziert klein halten\n",
    "            X_tab, y_tab = X_train_vec, y_train\n",
    "            if X_train_vec.shape[0] > TABPFN_MAX_SAMPLES:\n",
    "                sss = StratifiedShuffleSplit(n_splits=1, train_size=TABPFN_MAX_SAMPLES, random_state=RANDOM_STATE)\n",
    "                idx, _ = next(sss.split(X_train_vec, y_train))\n",
    "                X_tab = X_train_vec[idx]\n",
    "                y_tab = np.asarray(y_train)[idx]\n",
    "            print(f\"[{name}] train subset: {X_tab.shape[0]} rows\")\n",
    "\n",
    "            # SVD -> float32\n",
    "            t0 = time.perf_counter()\n",
    "            svd = TruncatedSVD(n_components=TABPFN_N_COMPONENTS, random_state=RANDOM_STATE)\n",
    "            X_train_svd = svd.fit_transform(X_tab).astype(\"float32\", copy=False)\n",
    "            X_test_svd  = svd.transform(X_test_vec).astype(\"float32\", copy=False)\n",
    "            print(f\"[{name}] SVD train={X_train_svd.shape}, test={X_test_svd.shape} in {time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "            # Fit\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(X_train_svd, y_tab)\n",
    "            if USE_CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s (device={'cuda' if USE_CUDA else 'cpu'})\")\n",
    "\n",
    "            # Evaluate (batched predict; kein zweites predict in evaluate_model)\n",
    "            res = evaluate_model(model, X_test_svd, y_test, f\"{name}-{ds_name}\",\n",
    "                                 use_batches=True, batch_size=TABPFN_BATCH)\n",
    "            results.append(res)\n",
    "            print(res)\n",
    "\n",
    "        else:\n",
    "            # RF, MLP, XGB: direkt auf Sparse\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(X_train_vec, y_train)\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s\")\n",
    "            res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "            results.append(res)\n",
    "            print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574d3c4",
   "metadata": {},
   "source": [
    "# Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8e411",
   "metadata": {},
   "source": [
    "## Ergebnistabelle ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bb883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] CUDA avail: True | Torch CUDA build: 12.1\n",
      "\n",
      "======================================================================\n",
      "DATASET: SQL\n",
      "[DATA] rows=30844 | pos=11334 | neg=19510\n",
      "[VEC] TF-IDF train=(24675, 50000), test=(6169, 50000) in 1.11s\n",
      "--------------------------------------------------\n",
      "MODEL: RandomForest on SQL\n",
      "[RandomForest] fit in 19.61s\n",
      "→ Evaluate RandomForest-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'RandomForest-SQL', 'Pred_s': 0.8788560000248253, 'Precision': 0.9917172832689122, 'Recall': 0.792236435818262, 'F1': 0.8808239333006376, 'FPR': 0.0038441824705279346, 'FNR': 0.20776356418173797}\n",
      "--------------------------------------------------\n",
      "MODEL: MLP on SQL\n",
      "[MLP] fit in 757.34s\n",
      "→ Evaluate MLP-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'MLP-SQL', 'Pred_s': 0.02263869997113943, 'Precision': 0.9911894273127754, 'Recall': 0.7940008822232024, 'F1': 0.881704628949302, 'FPR': 0.004100461301896463, 'FNR': 0.20599911777679752}\n",
      "--------------------------------------------------\n",
      "MODEL: XGBoost on SQL\n",
      "[XGBoost] fit in 9.68s\n",
      "→ Evaluate XGBoost-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'XGBoost-SQL', 'Pred_s': 0.02705979999154806, 'Precision': 1.0, 'Recall': 0.4239082487869431, 'F1': 0.5954151177199505, 'FPR': 0.0, 'FNR': 0.5760917512130569}\n",
      "--------------------------------------------------\n",
      "MODEL: CatBoost on SQL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [16:43:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] fit in 135.72s\n",
      "→ Evaluate CatBoost-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'CatBoost-SQL', 'Pred_s': 0.11959089990705252, 'Precision': 1.0, 'Recall': 0.7878253198059109, 'F1': 0.8813224771773994, 'FPR': 0.0, 'FNR': 0.2121746801940891}\n",
      "--------------------------------------------------\n",
      "MODEL: TabPFN on SQL\n",
      "[TabPFN] train subset: 4000 rows\n",
      "[TabPFN] SVD train=(4000, 150), test=(6169, 150) in 2.76s\n",
      "[TabPFN] fit in 117.52s (device=cuda)\n",
      "→ Evaluate TabPFN-SQL on X_test=(6169, 150)\n",
      "   [predict] batch   1/49 (128 rows) in 55.93s\n",
      "   [predict] batch   2/49 (128 rows) in 75.43s\n",
      "   [predict] batch   3/49 (128 rows) in 54.81s\n",
      "   [predict] batch   4/49 (128 rows) in 53.84s\n",
      "   [predict] batch   5/49 (128 rows) in 61.57s\n",
      "   [predict] batch   6/49 (128 rows) in 53.88s\n",
      "   [predict] batch   7/49 (128 rows) in 34.88s\n",
      "   [predict] batch   8/49 (128 rows) in 50.25s\n",
      "   [predict] batch   9/49 (128 rows) in 50.79s\n",
      "   [predict] batch  10/49 (128 rows) in 67.98s\n",
      "   [predict] batch  11/49 (128 rows) in 44.10s\n",
      "   [predict] batch  12/49 (128 rows) in 41.30s\n",
      "   [predict] batch  13/49 (128 rows) in 36.58s\n",
      "   [predict] batch  14/49 (128 rows) in 42.51s\n",
      "   [predict] batch  15/49 (128 rows) in 37.25s\n",
      "   [predict] batch  16/49 (128 rows) in 40.19s\n",
      "   [predict] batch  17/49 (128 rows) in 51.46s\n",
      "   [predict] batch  18/49 (128 rows) in 31.44s\n",
      "   [predict] batch  19/49 (128 rows) in 26.62s\n",
      "   [predict] batch  20/49 (128 rows) in 26.65s\n",
      "   [predict] batch  21/49 (128 rows) in 26.71s\n",
      "   [predict] batch  22/49 (128 rows) in 26.76s\n",
      "   [predict] batch  23/49 (128 rows) in 26.86s\n",
      "   [predict] batch  24/49 (128 rows) in 26.86s\n",
      "   [predict] batch  25/49 (128 rows) in 26.72s\n",
      "   [predict] batch  26/49 (128 rows) in 31.41s\n",
      "   [predict] batch  27/49 (128 rows) in 34.56s\n",
      "   [predict] batch  28/49 (128 rows) in 33.24s\n",
      "   [predict] batch  29/49 (128 rows) in 33.47s\n",
      "   [predict] batch  30/49 (128 rows) in 34.32s\n",
      "   [predict] batch  31/49 (128 rows) in 33.91s\n",
      "   [predict] batch  32/49 (128 rows) in 33.38s\n",
      "   [predict] batch  33/49 (128 rows) in 33.15s\n",
      "   [predict] batch  34/49 (128 rows) in 34.15s\n",
      "   [predict] batch  35/49 (128 rows) in 34.23s\n",
      "   [predict] batch  36/49 (128 rows) in 34.20s\n",
      "   [predict] batch  37/49 (128 rows) in 42.19s\n",
      "   [predict] batch  38/49 (128 rows) in 33.38s\n",
      "   [predict] batch  39/49 (128 rows) in 26.98s\n",
      "   [predict] batch  40/49 (128 rows) in 26.58s\n",
      "   [predict] batch  41/49 (128 rows) in 27.17s\n",
      "   [predict] batch  42/49 (128 rows) in 26.61s\n",
      "   [predict] batch  43/49 (128 rows) in 27.10s\n",
      "   [predict] batch  44/49 (128 rows) in 28.74s\n",
      "   [predict] batch  45/49 (128 rows) in 33.17s\n",
      "   [predict] batch  46/49 (128 rows) in 26.66s\n",
      "   [predict] batch  47/49 (128 rows) in 26.54s\n",
      "   [predict] batch  48/49 (128 rows) in 26.61s\n",
      "   [predict] batch  49/49 (25 rows) in 103.04s\n",
      "{'Model': 'TabPFN-SQL', 'Pred_s': 1896.1656388998963, 'Precision': 1.0, 'Recall': 0.7847375385972651, 'F1': 0.879387048937222, 'FPR': 0.0, 'FNR': 0.2152624614027349}\n",
      "\n",
      "======================================================================\n",
      "DATASET: XSS\n",
      "[DATA] rows=13686 | pos=7373 | neg=6313\n",
      "[VEC] TF-IDF train=(10948, 50000), test=(2738, 50000) in 1.07s\n",
      "--------------------------------------------------\n",
      "MODEL: RandomForest on XSS\n",
      "[RandomForest] fit in 2.23s\n",
      "→ Evaluate RandomForest-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'RandomForest-XSS', 'Pred_s': 0.1320118997246027, 'Precision': 1.0, 'Recall': 0.9450847457627118, 'F1': 0.9717671662600209, 'FPR': 0.0, 'FNR': 0.05491525423728814}\n",
      "--------------------------------------------------\n",
      "MODEL: MLP on XSS\n",
      "[MLP] fit in 299.90s\n",
      "→ Evaluate MLP-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'MLP-XSS', 'Pred_s': 0.011133000254631042, 'Precision': 0.999288256227758, 'Recall': 0.951864406779661, 'F1': 0.975, 'FPR': 0.000791765637371338, 'FNR': 0.04813559322033898}\n",
      "--------------------------------------------------\n",
      "MODEL: XGBoost on XSS\n",
      "[XGBoost] fit in 30.82s\n",
      "→ Evaluate XGBoost-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'XGBoost-XSS', 'Pred_s': 0.02666549989953637, 'Precision': 0.6463628396143734, 'Recall': 1.0, 'F1': 0.7852009582113388, 'FPR': 0.6389548693586699, 'FNR': 0.0}\n",
      "--------------------------------------------------\n",
      "MODEL: CatBoost on XSS\n",
      "[CatBoost] fit in 128.71s\n",
      "→ Evaluate CatBoost-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'CatBoost-XSS', 'Pred_s': 0.08293340029194951, 'Precision': 1.0, 'Recall': 0.9464406779661017, 'F1': 0.9724834552420759, 'FPR': 0.0, 'FNR': 0.05355932203389831}\n",
      "--------------------------------------------------\n",
      "MODEL: TabPFN on XSS\n",
      "[TabPFN] train subset: 4000 rows\n",
      "[TabPFN] SVD train=(4000, 150), test=(2738, 150) in 2.43s\n",
      "[TabPFN] fit in 55.83s (device=cuda)\n",
      "→ Evaluate TabPFN-XSS on X_test=(2738, 150)\n",
      "   [predict] batch   1/22 (128 rows) in 51.77s\n",
      "   [predict] batch   2/22 (128 rows) in 47.37s\n",
      "   [predict] batch   3/22 (128 rows) in 43.83s\n",
      "   [predict] batch   4/22 (128 rows) in 43.47s\n",
      "   [predict] batch   5/22 (128 rows) in 39.92s\n",
      "   [predict] batch   6/22 (128 rows) in 43.59s\n",
      "   [predict] batch   7/22 (128 rows) in 35.74s\n",
      "   [predict] batch   8/22 (128 rows) in 31.09s\n",
      "   [predict] batch   9/22 (128 rows) in 25.98s\n",
      "   [predict] batch  10/22 (128 rows) in 26.18s\n",
      "   [predict] batch  11/22 (128 rows) in 26.20s\n",
      "   [predict] batch  12/22 (128 rows) in 29.99s\n",
      "   [predict] batch  13/22 (128 rows) in 27.28s\n",
      "   [predict] batch  14/22 (128 rows) in 29.67s\n",
      "   [predict] batch  15/22 (128 rows) in 27.22s\n",
      "   [predict] batch  16/22 (128 rows) in 26.09s\n",
      "   [predict] batch  17/22 (128 rows) in 26.11s\n",
      "   [predict] batch  18/22 (128 rows) in 29.66s\n",
      "   [predict] batch  19/22 (128 rows) in 28.41s\n",
      "   [predict] batch  20/22 (128 rows) in 29.64s\n",
      "   [predict] batch  21/22 (128 rows) in 27.26s\n",
      "   [predict] batch  22/22 (50 rows) in 64.09s\n",
      "{'Model': 'TabPFN-XSS', 'Pred_s': 760.5945712998509, 'Precision': 1.0, 'Recall': 0.9423728813559322, 'F1': 0.9703315881326352, 'FPR': 0.0, 'FNR': 0.0576271186440678}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pred_s</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost-SQL</td>\n",
       "      <td>0.119591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787825</td>\n",
       "      <td>0.881322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost-XSS</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946441</td>\n",
       "      <td>0.972483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP-SQL</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.991189</td>\n",
       "      <td>0.794001</td>\n",
       "      <td>0.881705</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.205999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-XSS</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.951864</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.048136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest-SQL</td>\n",
       "      <td>0.878856</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.792236</td>\n",
       "      <td>0.880824</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.207764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest-XSS</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945085</td>\n",
       "      <td>0.971767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TabPFN-SQL</td>\n",
       "      <td>1896.165639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784738</td>\n",
       "      <td>0.879387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TabPFN-XSS</td>\n",
       "      <td>760.594571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942373</td>\n",
       "      <td>0.970332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost-SQL</td>\n",
       "      <td>0.027060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423908</td>\n",
       "      <td>0.595415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost-XSS</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.646363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785201</td>\n",
       "      <td>0.638955</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       Pred_s  Precision    Recall        F1       FPR  \\\n",
       "0      CatBoost-SQL     0.119591   1.000000  0.787825  0.881322  0.000000   \n",
       "1      CatBoost-XSS     0.082933   1.000000  0.946441  0.972483  0.000000   \n",
       "2           MLP-SQL     0.022639   0.991189  0.794001  0.881705  0.004100   \n",
       "3           MLP-XSS     0.011133   0.999288  0.951864  0.975000  0.000792   \n",
       "4  RandomForest-SQL     0.878856   0.991717  0.792236  0.880824  0.003844   \n",
       "5  RandomForest-XSS     0.132012   1.000000  0.945085  0.971767  0.000000   \n",
       "6        TabPFN-SQL  1896.165639   1.000000  0.784738  0.879387  0.000000   \n",
       "7        TabPFN-XSS   760.594571   1.000000  0.942373  0.970332  0.000000   \n",
       "8       XGBoost-SQL     0.027060   1.000000  0.423908  0.595415  0.000000   \n",
       "9       XGBoost-XSS     0.026665   0.646363  1.000000  0.785201  0.638955   \n",
       "\n",
       "        FNR  \n",
       "0  0.212175  \n",
       "1  0.053559  \n",
       "2  0.205999  \n",
       "3  0.048136  \n",
       "4  0.207764  \n",
       "5  0.054915  \n",
       "6  0.215262  \n",
       "7  0.057627  \n",
       "8  0.576092  \n",
       "9  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    189\u001b[39m display(df_results.sort_values([\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    190\u001b[39m df_results.to_csv(\u001b[33m\"\u001b[39m\u001b[33mresults_all.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresults_all.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m    192\u001b[39m     df_results.to_excel(w, sheet_name=\u001b[33m\"\u001b[39m\u001b[33mAll\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Ergebnisse gespeichert: results_all.csv / results_all.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:57\u001b[39m, in \u001b[36mOpenpyxlWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     46\u001b[39m     path: FilePath | WriteExcelBuffer | ExcelWriter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[32m     59\u001b[39m     engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m     61\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     62\u001b[39m         path,\n\u001b[32m     63\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m         engine_kwargs=engine_kwargs,\n\u001b[32m     67\u001b[39m     )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "# Ergebnis-Tabelle ausgeben\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values([\"Model\"]).reset_index(drop=True))\n",
    "df_results.to_csv(\"results_all.csv\", index=False)\n",
    "with pd.ExcelWriter(\"results_all.xlsx\") as w:\n",
    "    df_results.to_excel(w, sheet_name=\"All\", index=False)\n",
    "print(\" Ergebnisse gespeichert: results_all.csv / results_all.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f721a",
   "metadata": {},
   "source": [
    "## Ergebnisse speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4caea88",
   "metadata": {},
   "source": [
    "## Ergebnistabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd-DataFrame(results)\n",
    "results_df.sort_values([\"Model\"], inplace=True)\n",
    "print(\"\\n Gesamt Ergebnisse: \\n\", results_df)\n",
    "\n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4015df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Variante A – wenn df_results bereits eine 'Dataset'-Spalte hat\n",
    "if \"Dataset\" in df_results.columns:\n",
    "    df_sql = df_results[df_results[\"Dataset\"] == \"SQL\"].copy()\n",
    "    df_xss = df_results[df_results[\"Dataset\"] == \"XSS\"].copy()\n",
    "# Variante B – Spalte fehlt -> am Modell-Namen aufteilen\n",
    "else:\n",
    "    df_sql = df_results[df_results[\"Model\"].str.contains(\"-SQL\")].copy()\n",
    "    df_xss = df_results[df_results[\"Model\"].str.contains(\"-XSS\")].copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) zwei CSV-Dateien \n",
    "# ------------------------------------------------------------\n",
    "df_sql.to_csv(\"results_sql.csv\", index=False, sep=\";\")\n",
    "df_xss.to_csv(\"results_xss.csv\", index=False, sep=\";\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Excel-Workbook mit zwei Sheets\n",
    "# ------------------------------------------------------------\n",
    "with pd.ExcelWriter(\"results_by_dataset.xlsx\") as writer:\n",
    "    df_sql.to_excel(writer, sheet_name=\"SQL\", index=False)\n",
    "    df_xss.to_excel(writer, sheet_name=\"XSS\", index=False)\n",
    "\n",
    "print( \"Dateien wurden exportiert: results_sql.csv, results_xss.csv, results_by_dataset.xlsx\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c2ae6",
   "metadata": {},
   "source": [
    "## Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd3b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd036337",
   "metadata": {},
   "source": [
    "## K-Fold-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae0362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
