{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41cdae0",
   "metadata": {},
   "source": [
    "# Code zu der Bachelorarbeit:\n",
    "# \"Comparitve Study von Machine Learning Modellen zur Erkennung von Web Schwachstellen\"\n",
    "## von Nils Pudenz, 2735230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512b38",
   "metadata": {},
   "source": [
    "# Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%pip install kaggle scikit-learn xgboost catboost tabpfn pandas numpy matplotlib seaborn -q\n",
    "#%pip install --quiet scikit-learn xgboost catboost tabpfn chardet\n",
    "#%pip install -U scikit-learn\n",
    "## in deiner (Conda/venv) Umgebung\n",
    "#%pip install --upgrade \"torch==2.*\" --index-url https://download.pytorch.org/whl/cu121\n",
    "#%pip install --upgrade xgboost catboost scikit-learn pandas scipy tabpfn\n",
    "##wenn es komplikationen mit torch gibt, deiinstallieren und neu installieren\n",
    "#%pip uninstall torch\n",
    "#%pip install torch --index-url https://download.pytorch.org/whl/cu121 --upgrade\n",
    "#%pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1546ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, joblib\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5103769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "CUDA verfügbar: True\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(\"CUDA verfügbar:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b9e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Scripts\\python.exe\n",
      "Torch: 2.5.1+cu121 | CUDA build: 12.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\", sys.executable)\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06596acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deterministische Ausgabe generieren, um die Reproduzierbarkeit zu gewährleisten\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb571069",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"         # OpenMP\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8724d98",
   "metadata": {},
   "source": [
    "## Dowload Kaggle Datasets\n",
    "Requires Kaggle API credentials ('~/.kaggle/kaggle.json') für API-Token, um zugriff auf die Datenbanken über das Kaggle Konto zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742eb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dowload der Datasets von Kaggle, Output =1 erfoglgreich, Output = 0 fehlerhaft\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/sql-injection-dataset -p data --unzip --quiet\")\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning -p data --unzip --quiet\")\n",
    "#KAGGLE_DATASETS = { #gleich wie oben nur renaming auf sql & xss\n",
    "#    \"sql\": \"syedsaqlainhussain/sql-injection-dataset\",\n",
    "#    \"xss\": \"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461379a7",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705be12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CSV = Path(r\"data\\SQLiV3.csv\") #next(DATA_DIR.glob(\"**/sql*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*SQL*.csv\"), None)\n",
    "XSS_CSV = next(DATA_DIR.glob(\"**/xss*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*XSS*.csv\"), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ebfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to dataframe\n",
    "sql_df = pd.read_csv(SQL_CSV) #, encoding=\"utf-16\", sep=\",\", low_memory=False) #utf-8 Fehler\n",
    "xss_df = pd.read_csv(XSS_CSV)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aeabd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL dataset shape: (30919, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" or pg_sleep  (  __TIME__  )  --</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create user name identified by pass123 tempora...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND 1  =  utl_inaddr.get_host_address   (    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select * from users where id  =  '1' or @ @1 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select * from users where id  =  1 or 1#\"  ( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Label Unnamed: 2  \\\n",
       "0                  \" or pg_sleep  (  __TIME__  )  --     1        NaN   \n",
       "1  create user name identified by pass123 tempora...   NaN          1   \n",
       "2   AND 1  =  utl_inaddr.get_host_address   (    ...     1        NaN   \n",
       "3   select * from users where id  =  '1' or @ @1 ...     1        NaN   \n",
       "4   select * from users where id  =  1 or 1#\"  ( ...     1        NaN   \n",
       "\n",
       "   Unnamed: 3  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.440959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 3\n",
       "count    9.000000\n",
       "mean     0.222222\n",
       "std      0.440959\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      0.000000\n",
       "max      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XSS dataset shape: (13686, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;li&gt;&lt;a href=\"/wiki/File:Socrates.png\" class=\"i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;tt onmouseover=\"alert(1)\"&gt;test&lt;/tt&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;Steeri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;&lt;cite ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\t &lt;/span&gt;. &lt;a href=\"/wiki/Digital_object_iden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Sentence  Label\n",
       "0           0  <li><a href=\"/wiki/File:Socrates.png\" class=\"i...      0\n",
       "1           1               <tt onmouseover=\"alert(1)\">test</tt>      1\n",
       "2           2  \\t </span> <span class=\"reference-text\">Steeri...      0\n",
       "3           3  \\t </span> <span class=\"reference-text\"><cite ...      0\n",
       "4           4  \\t </span>. <a href=\"/wiki/Digital_object_iden...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13686.000000</td>\n",
       "      <td>13686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6842.500000</td>\n",
       "      <td>0.538726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3950.952227</td>\n",
       "      <td>0.498516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3421.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6842.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10263.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13685.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         Label\n",
       "count  13686.000000  13686.000000\n",
       "mean    6842.500000      0.538726\n",
       "std     3950.952227      0.498516\n",
       "min        0.000000      0.000000\n",
       "25%     3421.250000      0.000000\n",
       "50%     6842.500000      1.000000\n",
       "75%    10263.750000      1.000000\n",
       "max    13685.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, df in {\"SQL\": sql_df, \"XSS\": xss_df}.items():\n",
    "    print(f\"{name} dataset shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d30aa",
   "metadata": {},
   "source": [
    "## Basic Cleaning\n",
    "* Drop Duplicate rows\n",
    "* Handle missing values (simple fill-na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3c78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentence', 'Label', 'Unnamed: 2', 'Unnamed: 3']\n",
      "clean shape: (30873, 2)\n",
      "Label\n",
      "0                                                                         0.628891\n",
      "1                                                                         0.370162\n",
      " --                                                                       0.000359\n",
      "waitfor delay '0:0:__TIME__'--                                            0.000131\n",
      " DROP TABLE Suppliers                                                     0.000065\n",
      " desc users                                                               0.000033\n",
      "SELECT *                                                                  0.000033\n",
      " OR                                                                       0.000033\n",
      " if not  (  select system_user  )   <> 'sa' waitfor delay '0:0:2' --      0.000033\n",
      " drop table temp --                                                       0.000033\n",
      " grant resource to name                                                   0.000033\n",
      " /*Select all the columns of all the records in the Customers table:*/    0.000033\n",
      " EXEC SelectAllCustomers                                                  0.000033\n",
      "*/                                                                        0.000033\n",
      " CREATE VIEW [Products Above Average Price] AS                            0.000033\n",
      " CREATE OR REPLACE VIEW view_name AS                                      0.000033\n",
      " SELECT column_name ( s )                                                 0.000033\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Spalten ansehen\n",
    "print(sql_df.columns.tolist())\n",
    "\n",
    "# Typische Index-/Hilfsspalten loswerden\n",
    "sql_df = sql_df.loc[:, ~sql_df.columns.str.contains(r\"^Unnamed|^index$\", case=False)]\n",
    "\n",
    "# Auf die Kernspalten reduzieren (falls etwas anderes drin ist)\n",
    "sql_df = sql_df[[\"Sentence\", \"Label\"]].copy()\n",
    "\n",
    "# Optional: Duplikate auf Satzebene entfernen (falls noch nicht passiert)\n",
    "sql_df = sql_df.drop_duplicates(subset=[\"Sentence\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"clean shape:\", sql_df.shape)  # Erwartung: (30873, 2)\n",
    "print(sql_df[\"Label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce598302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (sql_df, xss_df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5eedf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xy(df: pd.DataFrame,\n",
    "                  label_candidates=(\"label\", \"class\", \"target\"),\n",
    "                  label_map=None):\n",
    "    if label_map is None:\n",
    "        label_map = {\n",
    "            \"0\": \"0\", \"1\": \"1\",\n",
    "            \"benign\": \"0\", \"normal\": \"0\", \"legitimate\": \"0\", \"safe\": \"0\",\n",
    "            \"attack\": \"1\", \"malicious\": \"1\", \"sql injection\": \"1\",\n",
    "            \"sql-injection\": \"1\", \"xss\": \"1\"\n",
    "        }\n",
    "\n",
    "    # Zielspalte finden (im *übergebenen* df!)\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    target_col = next((cols_lower[c] for c in label_candidates if c in cols_lower), None)\n",
    "    if target_col is None:\n",
    "        raise ValueError(f\"Keine Label-Spalte gefunden. Kandidaten: {label_candidates}\")\n",
    "\n",
    "    # Labels normieren -> nur 0/1 behalten\n",
    "    y_str = df[target_col].astype(str).str.strip().str.lower()\n",
    "    y_map = y_str.map(label_map)\n",
    "    mask = y_map.notna()\n",
    "    y = pd.to_numeric(y_map[mask]).astype(int).to_numpy()\n",
    "\n",
    "    # Rohtext aus allen Nicht-Label-Spalten zusammenbauen\n",
    "    feat_cols = [c for c in df.columns if c != target_col]\n",
    "    X_raw = df.loc[mask, feat_cols].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    return X_raw, y, target_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb270e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\", ngram_range=(3,5), min_df=2, max_features=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ebf89",
   "metadata": {},
   "source": [
    "## Splitting & Measure-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b3207c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    X = df[FEATURES].values\n",
    "    y = df[target_col].astype(int).values\n",
    "    return train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a217b",
   "metadata": {},
   "source": [
    "Erst den Datensatz splitten, um Data Leakage vorzubeugen, Wujek et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1ac042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "\n",
    "    \"\"\"Evaluiert das Modell und gibt ein dic mit den Metriken zurück.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    return dict(Model=name, Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d697d2",
   "metadata": {},
   "source": [
    "Dictionary für die Evaulierungsmetriken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fea7e",
   "metadata": {},
   "source": [
    "## Modeldefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7d55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<joblib.parallel.parallel_backend at 0x213756f6610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'''# Parallelisierung der Modelle für bessere Laufzeit\n",
    "\n",
    "# scikit-learn / joblib\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"         # OpenMP\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"    # NumPy / SciPy\n",
    "joblib.parallel_backend(\"loky\", n_jobs=-1)  # überall -1 = alle Kerne\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f16504",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xgb = XGBClassifier(\n",
    "    tree_method=\"hist\",        # CPU-Optimierung\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=400,\n",
    "    depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=42,\n",
    "    loss_function=\"Logloss\",\n",
    "    task_type=\"CPU\",\n",
    "    thread_count=8,\n",
    "    od_type=\"Iter\",            # early stopping\n",
    "    od_wait=30,\n",
    "    verbose=False\n",
    ")\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speicher optimieren\n",
    "'''\n",
    "vec = TfidfVectorizer(\n",
    "    ngram_range=(3,5),\n",
    "    max_features=50_000,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=False\n",
    ").fit(X_train_raw)           # nur einmal fitten\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb31025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kleine Hyperparamsuche statt Grid-Overkill\n",
    "'''\n",
    "search_space = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [200, 400, 600]\n",
    "}\n",
    "randcv = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    search_space,\n",
    "    n_iter=10,            # statt 3×3×3 = 27\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "randcv.fit(X_train_vec, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ed55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3454871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\n",
    "\"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "#\"MLP\": MLPClassifier(hidden_layer_sizes=(512, 256), activation=\"relu\", alpha= 1e-4, learning_rate_init=1e-3, early_stopping=True, random_state=RANDOM_STATE, max_iter=30),\n",
    "#\"XGBoost\": XGBClassifier(n_estimators=500, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "#\"CatBoost\": CatBoostClassifier(iterations=400, depth=8, learning_rate=0.1, loss_function=\"Logloss\", random_seed=RANDOM_STATE, verbose=False),\n",
    "#\"TabPFN\": TabPFNClassifier(device=\"cpu\", ignore_pretraining_limits=True) # ingorieren der 500/10 000-Grenzen -> führt zu Absturz\n",
    "\n",
    "#-----GPU--------\n",
    "\"MLP\": MLPClassifier(hidden_layer_sizes=(256, 128), activation=\"relu\", early_stopping=True, random_state=RANDOM_STATE, max_iter=50),\n",
    "\"XGBoost\": XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, subsample=0.9, colsample_bytree=0.8, tree_method=\"hist\", device = \"cuda\", predictor=\"gpu_predictor\", random_state=RANDOM_STATE),\n",
    "#\"CatBoost\": CatBoostClassifier(iterations=500, depth=8, learning_rate=0.1, loss_function=\"Logloss\", task_type=\"GPU\", devices=\"0\", random_seed=RANDOM_STATE, verbose=False),\n",
    "\"TabPFN\": TabPFNClassifier(device=\"cuda\", ignore_pretraining_limits=True) #erlaubt >10k Samples / >500 Features\n",
    "\n",
    "\n",
    "#'''XXXX---- \n",
    "#'''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8da7b",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_s = pd.Series(y)\n",
    "#print(y_s.dtype)\n",
    "#print(y_s.apply(type).value_counts().head())      # zeigt gemischte Typen\n",
    "#print(y_s.value_counts(dropna=False).head(10))    # zeigt Labelwerte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369ec28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for df, ds_name in [(sql_df, \"SQL\"), (xss_df, \"XSS\")]:\n",
    "    X_raw, y, target_col = preprocess_xy(df) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_raw,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gemeinsmaer TF-IDF-Vectorizer (fit nur auf Train, wegen Oversampling)\n",
    "vec = vectorizer.fit(X_train)\n",
    "X_train_vec = vec.transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d283a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(model, X, batch_size=512): #um Überlastung zu vermeiden, evtl. 256 oder 128\n",
    "    \"\"\"Make predictions on input data in batches.\"\"\"\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        batch = X[i:i + batch_size]\n",
    "        preds.append(model.predict(batch))\n",
    "    return np.concatenate(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8ffe9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe89a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tabpfn import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ce09f",
   "metadata": {},
   "source": [
    "# Globale Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()  # für TabPFN & XGBoost\n",
    "print(f\"[ENV] CUDA avail: {USE_CUDA} | Torch CUDA build: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6d9eb",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bf05a",
   "metadata": {},
   "source": [
    "## Evaluationsmetriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba189305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_metrics(y_true, y_pred) -> dict:\n",
    "    \"\"\"Präzision/Recall/F1 & Raten (FPR/FNR) für binäre Klassifikation.\"\"\"\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    p  = precision_score(y_true, y_pred)\n",
    "    r  = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = float(fp / (fp + tn)) if (fp + tn) else 0.0\n",
    "    fnr = float(fn / (fn + tp)) if (fn + tp) else 0.0\n",
    "    return dict(Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, name, use_batches=False, batch_size=256) -> dict:\n",
    "    \"\"\"Zeitmessung + Vorhersage (optional in Batches) + Metriken.\"\"\"\n",
    "    print(f\"→ Evaluate {name} on X_test={getattr(X_test,'shape',None)}\")\n",
    "    t0 = time.perf_counter()\n",
    "    if use_batches:\n",
    "        y_pred = predict_in_batches(model, X_test, batch_size=batch_size, verbose=True)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    pred_s = time.perf_counter() - t0\n",
    "    m = binary_metrics(y_test, y_pred)\n",
    "    res = dict(Model=name, Pred_s=pred_s, **m)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c572f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10bd60",
   "metadata": {},
   "source": [
    "### Batchweise Vorhersage für TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(model, X, batch_size=256, verbose=False):\n",
    "    \"\"\"Vorhersage in Batches (schont RAM/VRAM; wichtig für TabPFN).\"\"\"\n",
    "    n = X.shape[0]\n",
    "    out = []\n",
    "    total = math.ceil(n / batch_size)\n",
    "    for b, i in enumerate(range(0, n, batch_size), start=1):\n",
    "        j = min(i + batch_size, n)\n",
    "        t1 = time.perf_counter()\n",
    "        with torch.inference_mode():\n",
    "            out.append(model.predict(X[i:j]))\n",
    "        dt = time.perf_counter() - t1\n",
    "        if verbose:\n",
    "            print(f\"   [predict] batch {b:>3}/{total} ({j-i} rows) in {dt:.2f}s\")\n",
    "        if USE_CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "    return np.concatenate(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e87bd",
   "metadata": {},
   "source": [
    "### Label bereinigung der Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(df, label_col=\"Label\", text_cols=(\"Sentence\",)):\n",
    "    \"\"\"Bringt Labels robust auf {0,1} und gibt (X_raw, y) zurück.\"\"\"\n",
    "    df = df.copy()\n",
    "    y_raw = df[label_col].astype(str).str.strip().str.lower()\n",
    "    map01 = {\"0\": \"0\", \"1\": \"1\", \"benign\": \"0\", \"normal\": \"0\", \"legitimate\": \"0\", \"safe\": \"0\",\n",
    "             \"attack\": \"1\", \"malicious\": \"1\", \"sql injection\": \"1\", \"sql-injection\": \"1\", \"xss\": \"1\"}\n",
    "    y_map = y_raw.map(map01)\n",
    "    mask = y_map.notna()\n",
    "    y = pd.to_numeric(y_map[mask]).astype(int).to_numpy()\n",
    "    feat_cols = [c for c in df.columns if c != label_col]\n",
    "    X_raw = df.loc[mask, feat_cols].astype(str).agg(\" \".join, axis=1)\n",
    "    return X_raw, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7b6ec",
   "metadata": {},
   "source": [
    "# Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18928fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(256,128), activation=\"relu\",\n",
    "                         early_stopping=True, n_iter_no_change=5, max_iter=200,\n",
    "                         random_state=RANDOM_STATE),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.1,\n",
    "        subsample=0.9, colsample_bytree=0.8,\n",
    "        tree_method=\"hist\", device=(\"cuda\" if USE_CUDA else \"cpu\"),\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostClassifier(\n",
    "        iterations=400, depth=8, learning_rate=0.1,\n",
    "        loss_function=\"Logloss\", random_seed=RANDOM_STATE, verbose=False,\n",
    "        task_type=\"CPU\"   # stabil über Pool + Sparse; bei GPU: task_type=\"GPU\" und ggf. Dense verwenden\n",
    "    ),\n",
    "    \"TabPFN\": TabPFNClassifier(\n",
    "        device=(\"cuda\" if USE_CUDA else \"cpu\"),\n",
    "        ignore_pretraining_limits=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690192f4",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_ARGS = dict(ngram_range=(3,5), max_features=50_000, sublinear_tf=True, lowercase=False)\n",
    "\n",
    "TABPFN_MAX_SAMPLES = 4000     # starte konservativ; später 6000/8000 testen\n",
    "TABPFN_N_COMPONENTS = 150     # <=500, kleiner = schneller/ram-sparender\n",
    "TABPFN_BATCH = 128            # Batch für Predict; 128/64 bei RAM-Engpässen\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c27db",
   "metadata": {},
   "source": [
    "## Pipeline je Datensatz (TF-IDF; TabPFN: SVD + batched predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df, ds_name in [(sql_df, \"SQL\"), (xss_df, \"XSS\")]:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"DATASET: {ds_name}\")\n",
    "\n",
    "    # Labels/Text\n",
    "    X_raw, y = clean_labels(df, label_col=\"Label\", text_cols=(\"Sentence\",))\n",
    "    print(f\"[DATA] rows={len(y)} | pos={int(y.sum())} | neg={len(y)-int(y.sum())}\")\n",
    "\n",
    "    # Split\n",
    "    X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # TF-IDF\n",
    "    vec = TfidfVectorizer(**VEC_ARGS)\n",
    "    t0 = time.perf_counter()\n",
    "    X_train_vec = vec.fit_transform(X_train_txt)\n",
    "    X_test_vec  = vec.transform(X_test_txt)\n",
    "    print(f\"[VEC] TF-IDF train={X_train_vec.shape}, test={X_test_vec.shape} in {time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "    # Modelle trainieren/evaluieren\n",
    "    for name, model in models.items():\n",
    "        print(\"-\"*50 + f\"\\nMODEL: {name} on {ds_name}\")\n",
    "\n",
    "        if name == \"CatBoost\":\n",
    "            # CatBoost stabil via Pool (sparse)\n",
    "            pool_train = Pool(X_train_vec, y_train)\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(pool_train)\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s\")\n",
    "            res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "            results.append(res)\n",
    "            print(res)\n",
    "\n",
    "        elif name == \"TabPFN\":\n",
    "            # ggf. Trainingsmenge stratifiziert klein halten\n",
    "            X_tab, y_tab = X_train_vec, y_train\n",
    "            if X_train_vec.shape[0] > TABPFN_MAX_SAMPLES:\n",
    "                sss = StratifiedShuffleSplit(n_splits=1, train_size=TABPFN_MAX_SAMPLES, random_state=RANDOM_STATE)\n",
    "                idx, _ = next(sss.split(X_train_vec, y_train))\n",
    "                X_tab = X_train_vec[idx]\n",
    "                y_tab = np.asarray(y_train)[idx]\n",
    "            print(f\"[{name}] train subset: {X_tab.shape[0]} rows\")\n",
    "\n",
    "            # SVD -> float32\n",
    "            t0 = time.perf_counter()\n",
    "            svd = TruncatedSVD(n_components=TABPFN_N_COMPONENTS, random_state=RANDOM_STATE)\n",
    "            X_train_svd = svd.fit_transform(X_tab).astype(\"float32\", copy=False)\n",
    "            X_test_svd  = svd.transform(X_test_vec).astype(\"float32\", copy=False)\n",
    "            print(f\"[{name}] SVD train={X_train_svd.shape}, test={X_test_svd.shape} in {time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "            # Fit\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(X_train_svd, y_tab)\n",
    "            if USE_CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s (device={'cuda' if USE_CUDA else 'cpu'})\")\n",
    "\n",
    "            # Evaluate (batched predict; kein zweites predict in evaluate_model)\n",
    "            res = evaluate_model(model, X_test_svd, y_test, f\"{name}-{ds_name}\",\n",
    "                                 use_batches=True, batch_size=TABPFN_BATCH)\n",
    "            results.append(res)\n",
    "            print(res)\n",
    "\n",
    "        else:\n",
    "            # RF, MLP, XGB: direkt auf Sparse\n",
    "            t0 = time.perf_counter()\n",
    "            model.fit(X_train_vec, y_train)\n",
    "            print(f\"[{name}] fit in {time.perf_counter()-t0:.2f}s\")\n",
    "            res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "            results.append(res)\n",
    "            print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574d3c4",
   "metadata": {},
   "source": [
    "# Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8e411",
   "metadata": {},
   "source": [
    "## Ergebnistabelle ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173bb883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] CUDA avail: True | Torch CUDA build: 12.1\n",
      "\n",
      "======================================================================\n",
      "DATASET: SQL\n",
      "[DATA] rows=30844 | pos=11334 | neg=19510\n",
      "[VEC] TF-IDF train=(24675, 50000), test=(6169, 50000) in 1.11s\n",
      "--------------------------------------------------\n",
      "MODEL: RandomForest on SQL\n",
      "[RandomForest] fit in 19.61s\n",
      "→ Evaluate RandomForest-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'RandomForest-SQL', 'Pred_s': 0.8788560000248253, 'Precision': 0.9917172832689122, 'Recall': 0.792236435818262, 'F1': 0.8808239333006376, 'FPR': 0.0038441824705279346, 'FNR': 0.20776356418173797}\n",
      "--------------------------------------------------\n",
      "MODEL: MLP on SQL\n",
      "[MLP] fit in 757.34s\n",
      "→ Evaluate MLP-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'MLP-SQL', 'Pred_s': 0.02263869997113943, 'Precision': 0.9911894273127754, 'Recall': 0.7940008822232024, 'F1': 0.881704628949302, 'FPR': 0.004100461301896463, 'FNR': 0.20599911777679752}\n",
      "--------------------------------------------------\n",
      "MODEL: XGBoost on SQL\n",
      "[XGBoost] fit in 9.68s\n",
      "→ Evaluate XGBoost-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'XGBoost-SQL', 'Pred_s': 0.02705979999154806, 'Precision': 1.0, 'Recall': 0.4239082487869431, 'F1': 0.5954151177199505, 'FPR': 0.0, 'FNR': 0.5760917512130569}\n",
      "--------------------------------------------------\n",
      "MODEL: CatBoost on SQL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [16:43:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] fit in 135.72s\n",
      "→ Evaluate CatBoost-SQL on X_test=(6169, 50000)\n",
      "{'Model': 'CatBoost-SQL', 'Pred_s': 0.11959089990705252, 'Precision': 1.0, 'Recall': 0.7878253198059109, 'F1': 0.8813224771773994, 'FPR': 0.0, 'FNR': 0.2121746801940891}\n",
      "--------------------------------------------------\n",
      "MODEL: TabPFN on SQL\n",
      "[TabPFN] train subset: 4000 rows\n",
      "[TabPFN] SVD train=(4000, 150), test=(6169, 150) in 2.76s\n",
      "[TabPFN] fit in 117.52s (device=cuda)\n",
      "→ Evaluate TabPFN-SQL on X_test=(6169, 150)\n",
      "   [predict] batch   1/49 (128 rows) in 55.93s\n",
      "   [predict] batch   2/49 (128 rows) in 75.43s\n",
      "   [predict] batch   3/49 (128 rows) in 54.81s\n",
      "   [predict] batch   4/49 (128 rows) in 53.84s\n",
      "   [predict] batch   5/49 (128 rows) in 61.57s\n",
      "   [predict] batch   6/49 (128 rows) in 53.88s\n",
      "   [predict] batch   7/49 (128 rows) in 34.88s\n",
      "   [predict] batch   8/49 (128 rows) in 50.25s\n",
      "   [predict] batch   9/49 (128 rows) in 50.79s\n",
      "   [predict] batch  10/49 (128 rows) in 67.98s\n",
      "   [predict] batch  11/49 (128 rows) in 44.10s\n",
      "   [predict] batch  12/49 (128 rows) in 41.30s\n",
      "   [predict] batch  13/49 (128 rows) in 36.58s\n",
      "   [predict] batch  14/49 (128 rows) in 42.51s\n",
      "   [predict] batch  15/49 (128 rows) in 37.25s\n",
      "   [predict] batch  16/49 (128 rows) in 40.19s\n",
      "   [predict] batch  17/49 (128 rows) in 51.46s\n",
      "   [predict] batch  18/49 (128 rows) in 31.44s\n",
      "   [predict] batch  19/49 (128 rows) in 26.62s\n",
      "   [predict] batch  20/49 (128 rows) in 26.65s\n",
      "   [predict] batch  21/49 (128 rows) in 26.71s\n",
      "   [predict] batch  22/49 (128 rows) in 26.76s\n",
      "   [predict] batch  23/49 (128 rows) in 26.86s\n",
      "   [predict] batch  24/49 (128 rows) in 26.86s\n",
      "   [predict] batch  25/49 (128 rows) in 26.72s\n",
      "   [predict] batch  26/49 (128 rows) in 31.41s\n",
      "   [predict] batch  27/49 (128 rows) in 34.56s\n",
      "   [predict] batch  28/49 (128 rows) in 33.24s\n",
      "   [predict] batch  29/49 (128 rows) in 33.47s\n",
      "   [predict] batch  30/49 (128 rows) in 34.32s\n",
      "   [predict] batch  31/49 (128 rows) in 33.91s\n",
      "   [predict] batch  32/49 (128 rows) in 33.38s\n",
      "   [predict] batch  33/49 (128 rows) in 33.15s\n",
      "   [predict] batch  34/49 (128 rows) in 34.15s\n",
      "   [predict] batch  35/49 (128 rows) in 34.23s\n",
      "   [predict] batch  36/49 (128 rows) in 34.20s\n",
      "   [predict] batch  37/49 (128 rows) in 42.19s\n",
      "   [predict] batch  38/49 (128 rows) in 33.38s\n",
      "   [predict] batch  39/49 (128 rows) in 26.98s\n",
      "   [predict] batch  40/49 (128 rows) in 26.58s\n",
      "   [predict] batch  41/49 (128 rows) in 27.17s\n",
      "   [predict] batch  42/49 (128 rows) in 26.61s\n",
      "   [predict] batch  43/49 (128 rows) in 27.10s\n",
      "   [predict] batch  44/49 (128 rows) in 28.74s\n",
      "   [predict] batch  45/49 (128 rows) in 33.17s\n",
      "   [predict] batch  46/49 (128 rows) in 26.66s\n",
      "   [predict] batch  47/49 (128 rows) in 26.54s\n",
      "   [predict] batch  48/49 (128 rows) in 26.61s\n",
      "   [predict] batch  49/49 (25 rows) in 103.04s\n",
      "{'Model': 'TabPFN-SQL', 'Pred_s': 1896.1656388998963, 'Precision': 1.0, 'Recall': 0.7847375385972651, 'F1': 0.879387048937222, 'FPR': 0.0, 'FNR': 0.2152624614027349}\n",
      "\n",
      "======================================================================\n",
      "DATASET: XSS\n",
      "[DATA] rows=13686 | pos=7373 | neg=6313\n",
      "[VEC] TF-IDF train=(10948, 50000), test=(2738, 50000) in 1.07s\n",
      "--------------------------------------------------\n",
      "MODEL: RandomForest on XSS\n",
      "[RandomForest] fit in 2.23s\n",
      "→ Evaluate RandomForest-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'RandomForest-XSS', 'Pred_s': 0.1320118997246027, 'Precision': 1.0, 'Recall': 0.9450847457627118, 'F1': 0.9717671662600209, 'FPR': 0.0, 'FNR': 0.05491525423728814}\n",
      "--------------------------------------------------\n",
      "MODEL: MLP on XSS\n",
      "[MLP] fit in 299.90s\n",
      "→ Evaluate MLP-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'MLP-XSS', 'Pred_s': 0.011133000254631042, 'Precision': 0.999288256227758, 'Recall': 0.951864406779661, 'F1': 0.975, 'FPR': 0.000791765637371338, 'FNR': 0.04813559322033898}\n",
      "--------------------------------------------------\n",
      "MODEL: XGBoost on XSS\n",
      "[XGBoost] fit in 30.82s\n",
      "→ Evaluate XGBoost-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'XGBoost-XSS', 'Pred_s': 0.02666549989953637, 'Precision': 0.6463628396143734, 'Recall': 1.0, 'F1': 0.7852009582113388, 'FPR': 0.6389548693586699, 'FNR': 0.0}\n",
      "--------------------------------------------------\n",
      "MODEL: CatBoost on XSS\n",
      "[CatBoost] fit in 128.71s\n",
      "→ Evaluate CatBoost-XSS on X_test=(2738, 50000)\n",
      "{'Model': 'CatBoost-XSS', 'Pred_s': 0.08293340029194951, 'Precision': 1.0, 'Recall': 0.9464406779661017, 'F1': 0.9724834552420759, 'FPR': 0.0, 'FNR': 0.05355932203389831}\n",
      "--------------------------------------------------\n",
      "MODEL: TabPFN on XSS\n",
      "[TabPFN] train subset: 4000 rows\n",
      "[TabPFN] SVD train=(4000, 150), test=(2738, 150) in 2.43s\n",
      "[TabPFN] fit in 55.83s (device=cuda)\n",
      "→ Evaluate TabPFN-XSS on X_test=(2738, 150)\n",
      "   [predict] batch   1/22 (128 rows) in 51.77s\n",
      "   [predict] batch   2/22 (128 rows) in 47.37s\n",
      "   [predict] batch   3/22 (128 rows) in 43.83s\n",
      "   [predict] batch   4/22 (128 rows) in 43.47s\n",
      "   [predict] batch   5/22 (128 rows) in 39.92s\n",
      "   [predict] batch   6/22 (128 rows) in 43.59s\n",
      "   [predict] batch   7/22 (128 rows) in 35.74s\n",
      "   [predict] batch   8/22 (128 rows) in 31.09s\n",
      "   [predict] batch   9/22 (128 rows) in 25.98s\n",
      "   [predict] batch  10/22 (128 rows) in 26.18s\n",
      "   [predict] batch  11/22 (128 rows) in 26.20s\n",
      "   [predict] batch  12/22 (128 rows) in 29.99s\n",
      "   [predict] batch  13/22 (128 rows) in 27.28s\n",
      "   [predict] batch  14/22 (128 rows) in 29.67s\n",
      "   [predict] batch  15/22 (128 rows) in 27.22s\n",
      "   [predict] batch  16/22 (128 rows) in 26.09s\n",
      "   [predict] batch  17/22 (128 rows) in 26.11s\n",
      "   [predict] batch  18/22 (128 rows) in 29.66s\n",
      "   [predict] batch  19/22 (128 rows) in 28.41s\n",
      "   [predict] batch  20/22 (128 rows) in 29.64s\n",
      "   [predict] batch  21/22 (128 rows) in 27.26s\n",
      "   [predict] batch  22/22 (50 rows) in 64.09s\n",
      "{'Model': 'TabPFN-XSS', 'Pred_s': 760.5945712998509, 'Precision': 1.0, 'Recall': 0.9423728813559322, 'F1': 0.9703315881326352, 'FPR': 0.0, 'FNR': 0.0576271186440678}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pred_s</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost-SQL</td>\n",
       "      <td>0.119591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787825</td>\n",
       "      <td>0.881322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost-XSS</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946441</td>\n",
       "      <td>0.972483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP-SQL</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.991189</td>\n",
       "      <td>0.794001</td>\n",
       "      <td>0.881705</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.205999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-XSS</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.951864</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.048136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest-SQL</td>\n",
       "      <td>0.878856</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>0.792236</td>\n",
       "      <td>0.880824</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.207764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest-XSS</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945085</td>\n",
       "      <td>0.971767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TabPFN-SQL</td>\n",
       "      <td>1896.165639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784738</td>\n",
       "      <td>0.879387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TabPFN-XSS</td>\n",
       "      <td>760.594571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942373</td>\n",
       "      <td>0.970332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost-SQL</td>\n",
       "      <td>0.027060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423908</td>\n",
       "      <td>0.595415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost-XSS</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.646363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785201</td>\n",
       "      <td>0.638955</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       Pred_s  Precision    Recall        F1       FPR  \\\n",
       "0      CatBoost-SQL     0.119591   1.000000  0.787825  0.881322  0.000000   \n",
       "1      CatBoost-XSS     0.082933   1.000000  0.946441  0.972483  0.000000   \n",
       "2           MLP-SQL     0.022639   0.991189  0.794001  0.881705  0.004100   \n",
       "3           MLP-XSS     0.011133   0.999288  0.951864  0.975000  0.000792   \n",
       "4  RandomForest-SQL     0.878856   0.991717  0.792236  0.880824  0.003844   \n",
       "5  RandomForest-XSS     0.132012   1.000000  0.945085  0.971767  0.000000   \n",
       "6        TabPFN-SQL  1896.165639   1.000000  0.784738  0.879387  0.000000   \n",
       "7        TabPFN-XSS   760.594571   1.000000  0.942373  0.970332  0.000000   \n",
       "8       XGBoost-SQL     0.027060   1.000000  0.423908  0.595415  0.000000   \n",
       "9       XGBoost-XSS     0.026665   0.646363  1.000000  0.785201  0.638955   \n",
       "\n",
       "        FNR  \n",
       "0  0.212175  \n",
       "1  0.053559  \n",
       "2  0.205999  \n",
       "3  0.048136  \n",
       "4  0.207764  \n",
       "5  0.054915  \n",
       "6  0.215262  \n",
       "7  0.057627  \n",
       "8  0.576092  \n",
       "9  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    189\u001b[39m display(df_results.sort_values([\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    190\u001b[39m df_results.to_csv(\u001b[33m\"\u001b[39m\u001b[33mresults_all.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresults_all.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m    192\u001b[39m     df_results.to_excel(w, sheet_name=\u001b[33m\"\u001b[39m\u001b[33mAll\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Ergebnisse gespeichert: results_all.csv / results_all.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nilsp\\Github_Desktop\\Comparative_Study_ML_WebVuln\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:57\u001b[39m, in \u001b[36mOpenpyxlWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     46\u001b[39m     path: FilePath | WriteExcelBuffer | ExcelWriter,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[32m     59\u001b[39m     engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m     61\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     62\u001b[39m         path,\n\u001b[32m     63\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m         engine_kwargs=engine_kwargs,\n\u001b[32m     67\u001b[39m     )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "# Ergebnis-Tabelle ausgeben\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values([\"Model\"]).reset_index(drop=True))\n",
    "df_results.to_csv(\"results_all.csv\", index=False)\n",
    "with pd.ExcelWriter(\"results_all.xlsx\") as w:\n",
    "    df_results.to_excel(w, sheet_name=\"All\", index=False)\n",
    "print(\" Ergebnisse gespeichert: results_all.csv / results_all.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f721a",
   "metadata": {},
   "source": [
    "## Ergebnisse speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b59b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def predict_in_batches(model, X, batch_size=128):\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        preds.append(model.predict(X[i:i+batch_size]))\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # ---------------------------------\n",
    "    # CatBoost\n",
    "    # ---------------------------------\n",
    "    if name == \"CatBoost\":\n",
    "        train_pool = Pool(X_train_vec, y_train)     # Sparse geht hier\n",
    "        model.fit(train_pool)\n",
    "        # CatBoost akzeptiert CSR im Predict:\n",
    "        res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "\n",
    "    # ---------------------------------\n",
    "    # TabPFN\n",
    "    # ---------------------------------\n",
    "    elif name == \"TabPFN\":\n",
    "        # 0) Threads zähmen (sonst gefühlt \"freeze\"), CUDA erzwingen\n",
    "        os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "        os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "        torch.set_num_threads(4)\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        model.set_params(device=\"cuda\" if use_cuda else \"cpu\",\n",
    "                        ignore_pretraining_limits=True)\n",
    "\n",
    "        # 1) Klein & sicher starten — später hochdrehen\n",
    "        MAX_SAMPLES = 4000      # <— erstmal klein\n",
    "        N_COMPONENTS = 150      # <— erstmal klein\n",
    "        BATCH = 128             # <— kleiner Batch schont (V)RAM\n",
    "\n",
    "        # ggf. stratifiziert reduzieren\n",
    "        X_train_tabpfn, y_train_tabpfn = X_train_vec, y_train\n",
    "        if X_train_vec.shape[0] > MAX_SAMPLES:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=MAX_SAMPLES, random_state=RANDOM_STATE)\n",
    "            idx, _ = next(sss.split(X_train_vec, y_train))\n",
    "            X_train_tabpfn = X_train_vec[idx]\n",
    "            y_train_tabpfn = np.asarray(y_train)[idx]\n",
    "\n",
    "        # 2) TF-IDF → SVD → float32 (kompakt)\n",
    "        svd = TruncatedSVD(n_components=N_COMPONENTS, random_state=RANDOM_STATE)\n",
    "        X_train_svd = svd.fit_transform(X_train_tabpfn).astype(\"float32\", copy=False)\n",
    "        X_test_svd  = svd.transform(X_test_vec).astype(\"float32\", copy=False)\n",
    "        assert np.isfinite(X_train_svd).all() and np.isfinite(X_test_svd).all()\n",
    "\n",
    "        print(f\"[TabPFN] device={'cuda' if use_cuda else 'cpu'} | train={X_train_svd.shape} | test={X_test_svd.shape}\")\n",
    "        if use_cuda:\n",
    "            print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "        # 3) Fit (kurz)\n",
    "        t0 = time.perf_counter()\n",
    "        model.fit(X_train_svd, y_train_tabpfn)\n",
    "        torch.cuda.synchronize() if use_cuda else None\n",
    "        print(f\"[TabPFN] fit done in {time.perf_counter()-t0:.1f}s\")\n",
    "\n",
    "        # 4) Predict in Batches — nur EINMAL! (keine evaluate_model() mehr)\n",
    "        def predict_in_batches(clf, X, batch_size=BATCH):\n",
    "            out = []\n",
    "            n = X.shape[0]\n",
    "            for i in range(0, n, batch_size):\n",
    "                j = min(i+batch_size, n)\n",
    "                t1 = time.perf_counter()\n",
    "                with torch.inference_mode():\n",
    "                    out.append(clf.predict(X[i:j]))\n",
    "                if use_cuda:\n",
    "                    torch.cuda.synchronize()\n",
    "                print(f\"[TabPFN] batch {i//batch_size+1}/{(n+batch_size-1)//batch_size} in {time.perf_counter()-t1:.2f}s\")\n",
    "            return np.concatenate(out)\n",
    "\n",
    "        y_pred = predict_in_batches(model, X_test_svd, batch_size=BATCH)\n",
    "        res = evaluate_model(model, X_test_svd, y_test, f\"{name}-{ds_name}\")\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Alle anderen Modelle\n",
    "    # ---------------------------------\n",
    "    else:\n",
    "        X_tr, X_te = X_train_vec, X_test_vec\n",
    "        model.fit(X_tr, y_train)\n",
    "        res = evaluate_model(model, X_te, y_test, f\"{name}-{ds_name}\")\n",
    "\n",
    "    results.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4caea88",
   "metadata": {},
   "source": [
    "## Ergebnistabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd-DataFrame(results)\n",
    "results_df.sort_values([\"Model\"], inplace=True)\n",
    "print(\"\\n Gesamt Ergebnisse: \\n\", results_df)\n",
    "\n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4015df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Variante A – wenn df_results bereits eine 'Dataset'-Spalte hat\n",
    "if \"Dataset\" in df_results.columns:\n",
    "    df_sql = df_results[df_results[\"Dataset\"] == \"SQL\"].copy()\n",
    "    df_xss = df_results[df_results[\"Dataset\"] == \"XSS\"].copy()\n",
    "# Variante B – Spalte fehlt -> am Modell-Namen aufteilen\n",
    "else:\n",
    "    df_sql = df_results[df_results[\"Model\"].str.contains(\"-SQL\")].copy()\n",
    "    df_xss = df_results[df_results[\"Model\"].str.contains(\"-XSS\")].copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) zwei CSV-Dateien \n",
    "# ------------------------------------------------------------\n",
    "df_sql.to_csv(\"results_sql.csv\", index=False, sep=\";\")\n",
    "df_xss.to_csv(\"results_xss.csv\", index=False, sep=\";\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Excel-Workbook mit zwei Sheets\n",
    "# ------------------------------------------------------------\n",
    "with pd.ExcelWriter(\"results_by_dataset.xlsx\") as writer:\n",
    "    df_sql.to_excel(writer, sheet_name=\"SQL\", index=False)\n",
    "    df_xss.to_excel(writer, sheet_name=\"XSS\", index=False)\n",
    "\n",
    "print( \"Dateien wurden exportiert: results_sql.csv, results_xss.csv, results_by_dataset.xlsx\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c2ae6",
   "metadata": {},
   "source": [
    "## Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd3b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd036337",
   "metadata": {},
   "source": [
    "## K-Fold-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae0362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
