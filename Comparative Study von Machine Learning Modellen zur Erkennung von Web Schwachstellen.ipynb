{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41cdae0",
   "metadata": {},
   "source": [
    "# Code zu der Bachelorarbeit:\n",
    "# \"Comparitve Study von Machine Learning Modellen zur Erkennung von Web Schwachstellen\"\n",
    "## von Nils Pudenz, 2735230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512b38",
   "metadata": {},
   "source": [
    "# Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install kaggle scikit-learn xgboost catboost tabpfn pandas numpy matplotlib seaborn -q\n",
    "#!pip install --quiet scikit-learn xgboost catboost tabpfn chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1546ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06596acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deterministische Ausgabe generieren, um die Reproduzierbarkeit zu gewährleisten\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8724d98",
   "metadata": {},
   "source": [
    "## Dowload Kaggle Datasets\n",
    "Requires Kaggle API credentials ('~/.kaggle/kaggle.json') für API-Token, um zugriff auf die Datenbanken über das Kaggle Konto zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742eb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dowload der Datasets von Kaggle\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/sql-injection-dataset -p data --unzip --quiet\")\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning -p data --unzip --quiet\")\n",
    "#KAGGLE_DATASETS = { #gleich wie oben nur renaming auf sql & xss\n",
    "#    \"sql\": \"syedsaqlainhussain/sql-injection-dataset\",\n",
    "#    \"xss\": \"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461379a7",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705be12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CSV = next(DATA_DIR.glob(\"**/sql*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*SQL*.csv\"), None)\n",
    "XSS_CSV = next(DATA_DIR.glob(\"**/xss*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*XSS*.csv\"), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to dataframe\n",
    "sql_df = pd.read_csv(SQL_CSV, encoding=\"utf-16\", sep=\",\", low_memory=False) #utf-8 Fehler\n",
    "xss_df = pd.read_csv(XSS_CSV)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeabd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in {\"SQL\": sql_df, \"XSS\": xss_df}.items():\n",
    "    print(f\"{name} dataset shape: {df.shape}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d30aa",
   "metadata": {},
   "source": [
    "## Basic Cleaning\n",
    "* Drop Duplicate rows\n",
    "* Handle missing values (simple fill-na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce598302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (sql_df, xss_df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449835a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xy(df: pd.DataFrame):\n",
    "    # Zielspalte finden und Features extrahieren\n",
    "    #Split in Features (roher Text) und Label-Vector.\n",
    "    target_col = next(c for c in sql_df.columns if c.lower() in {\"label\", \"class\", \"target\"})\n",
    "    X_raw = df.drop(columns=[target_col]).astype(str).agg(\" \".join, axis=1)\n",
    "    y = df[target_col].values\n",
    "    print(\"Target column assumed:\", target_col)\n",
    "    FEATURES = [c for c in sql_df.columns if c != target_col]\n",
    "    return X_raw, y, target_col\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd0331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb270e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\", ngram_range=(3,5), min_df=2, max_features=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ebf89",
   "metadata": {},
   "source": [
    "## Splitting & Measure-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3207c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    X = df[FEATURES].values\n",
    "    y = df[target_col].astype(int).values\n",
    "    return train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a217b",
   "metadata": {},
   "source": [
    "Erst den Datensatz splitten, um Data Leakage vorzubeugen, Wujek et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ac042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "\n",
    "    \"\"\"Evaluiert das Modell und gibt ein dic mit den Metriken zurück.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    return dict(Model=name, Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d697d2",
   "metadata": {},
   "source": [
    "Dictionary für die Evaulierungsmetriken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fea7e",
   "metadata": {},
   "source": [
    "## Modeldefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\n",
    "\"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "\"MLP\": MLPClassifier(hidden_layer_sizes=(512, 256), activation=\"relu\", alpha= 1e-4, learning_rate_init=1e-3, early_stopping=True, random_state=RANDOM_STATE, max_iter=30),\n",
    "\"XGBoost\": XGBClassifier(n_estimator=500, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "\"CatBoost\": CatBoostClassifier(iterations=400, depth=8, learning_rate=0.1, loss_function=\"Logsloss\", random_seed=RANDOM_STATE, verbose=False),\n",
    "\"TabPFN\": TabPFNClassifier(device=\"cpu\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8da7b",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ec28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for df, ds_name in [(sql_df, \"SQL\"), (xss_df, \"XSS\")]:\n",
    "    X_raw, y, target_col = preprocess_xy(df) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_raw,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gemeinsmaer TF-IDF-Vectorizer (fit nur auf Train, wegen Oversampling)\n",
    "vec = vectorizer.fit(X_train)\n",
    "X_train_vec = vec.transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    if name in {\"CatBoost\", \"TabPFN\"}:\n",
    "        # Dichte der Matrix erforderlich\n",
    "        model.fit(X_train_vec.toarray(), y_test, f\"{name}-{ds_name}\")\n",
    "    else:\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "    results.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4caea88",
   "metadata": {},
   "source": [
    "## Ergebnistabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd-DataFrame(results)\n",
    "results_df.sort_values([\"Model\"], inplace=True)\n",
    "print(\"\\n Gesamt Ergebnisse: \\n\", results_df)\n",
    "\n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c2ae6",
   "metadata": {},
   "source": [
    "## Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd3b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd036337",
   "metadata": {},
   "source": [
    "## K-Fold-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae0362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
