{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41cdae0",
   "metadata": {},
   "source": [
    "# Code zu der Bachelorarbeit:\n",
    "# \"Comparitve Study von Machine Learning Modellen zur Erkennung von Web Schwachstellen\"\n",
    "## von Nils Pudenz, 2735230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512b38",
   "metadata": {},
   "source": [
    "# Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6dac7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%pip install kaggle scikit-learn xgboost catboost tabpfn pandas numpy matplotlib seaborn -q\n",
    "#%pip install --quiet scikit-learn xgboost catboost tabpfn chardet\n",
    "#%pip install -U scikit-learn\n",
    "## in deiner (Conda/venv) Umgebung\n",
    "#%pip install --upgrade \"torch==2.*\" --index-url https://download.pytorch.org/whl/cu121\n",
    "#%pip install --upgrade xgboost catboost scikit-learn pandas scipy tabpfn\n",
    "\n",
    "#%pip uninstall torch\n",
    "#%pip install torch --index-url https://download.pytorch.org/whl/cu121 --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1546ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67173fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "model.set_params(device=\"cuda\" if use_cuda else \"cpu\",\n",
    "                 ignore_pretraining_limits=True)\n",
    "print(\"TabPFN device:\", \"cuda\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06596acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deterministische Ausgabe generieren, um die Reproduzierbarkeit zu gewährleisten\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb571069",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8724d98",
   "metadata": {},
   "source": [
    "## Dowload Kaggle Datasets\n",
    "Requires Kaggle API credentials ('~/.kaggle/kaggle.json') für API-Token, um zugriff auf die Datenbanken über das Kaggle Konto zu bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "742eb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "947e043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dowload der Datasets von Kaggle\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/sql-injection-dataset -p data --unzip --quiet\")\n",
    "os.system(\"kaggle datasets download -d syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning -p data --unzip --quiet\")\n",
    "#KAGGLE_DATASETS = { #gleich wie oben nur renaming auf sql & xss\n",
    "#    \"sql\": \"syedsaqlainhussain/sql-injection-dataset\",\n",
    "#    \"xss\": \"syedsaqlainhussain/cross-site-scripting-xss-dataset-for-deep-learning\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461379a7",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "705be12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_CSV = Path(r\"data\\SQLiV3.csv\") #next(DATA_DIR.glob(\"**/sql*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*SQL*.csv\"), None)\n",
    "XSS_CSV = next(DATA_DIR.glob(\"**/xss*/*.csv\"), None) or next(DATA_DIR.glob(\"**/*XSS*.csv\"), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58ebfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv to dataframe\n",
    "sql_df = pd.read_csv(SQL_CSV) #, encoding=\"utf-16\", sep=\",\", low_memory=False) #utf-8 Fehler\n",
    "xss_df = pd.read_csv(XSS_CSV)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0aeabd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL dataset shape: (30919, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" or pg_sleep  (  __TIME__  )  --</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create user name identified by pass123 tempora...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND 1  =  utl_inaddr.get_host_address   (    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select * from users where id  =  '1' or @ @1 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select * from users where id  =  1 or 1#\"  ( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Label Unnamed: 2  \\\n",
       "0                  \" or pg_sleep  (  __TIME__  )  --     1        NaN   \n",
       "1  create user name identified by pass123 tempora...   NaN          1   \n",
       "2   AND 1  =  utl_inaddr.get_host_address   (    ...     1        NaN   \n",
       "3   select * from users where id  =  '1' or @ @1 ...     1        NaN   \n",
       "4   select * from users where id  =  1 or 1#\"  ( ...     1        NaN   \n",
       "\n",
       "   Unnamed: 3  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.440959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 3\n",
       "count    9.000000\n",
       "mean     0.222222\n",
       "std      0.440959\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      0.000000\n",
       "max      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XSS dataset shape: (13686, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;li&gt;&lt;a href=\"/wiki/File:Socrates.png\" class=\"i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;tt onmouseover=\"alert(1)\"&gt;test&lt;/tt&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;Steeri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\t &lt;/span&gt; &lt;span class=\"reference-text\"&gt;&lt;cite ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\t &lt;/span&gt;. &lt;a href=\"/wiki/Digital_object_iden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Sentence  Label\n",
       "0           0  <li><a href=\"/wiki/File:Socrates.png\" class=\"i...      0\n",
       "1           1               <tt onmouseover=\"alert(1)\">test</tt>      1\n",
       "2           2  \\t </span> <span class=\"reference-text\">Steeri...      0\n",
       "3           3  \\t </span> <span class=\"reference-text\"><cite ...      0\n",
       "4           4  \\t </span>. <a href=\"/wiki/Digital_object_iden...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13686.000000</td>\n",
       "      <td>13686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6842.500000</td>\n",
       "      <td>0.538726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3950.952227</td>\n",
       "      <td>0.498516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3421.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6842.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10263.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13685.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         Label\n",
       "count  13686.000000  13686.000000\n",
       "mean    6842.500000      0.538726\n",
       "std     3950.952227      0.498516\n",
       "min        0.000000      0.000000\n",
       "25%     3421.250000      0.000000\n",
       "50%     6842.500000      1.000000\n",
       "75%    10263.750000      1.000000\n",
       "max    13685.000000      1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, df in {\"SQL\": sql_df, \"XSS\": xss_df}.items():\n",
    "    print(f\"{name} dataset shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d30aa",
   "metadata": {},
   "source": [
    "## Basic Cleaning\n",
    "* Drop Duplicate rows\n",
    "* Handle missing values (simple fill-na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a3c78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentence', 'Label', 'Unnamed: 2', 'Unnamed: 3']\n",
      "clean shape: (30873, 2)\n",
      "Label\n",
      "0                                                                         0.628891\n",
      "1                                                                         0.370162\n",
      " --                                                                       0.000359\n",
      "waitfor delay '0:0:__TIME__'--                                            0.000131\n",
      " DROP TABLE Suppliers                                                     0.000065\n",
      " desc users                                                               0.000033\n",
      "SELECT *                                                                  0.000033\n",
      " OR                                                                       0.000033\n",
      " if not  (  select system_user  )   <> 'sa' waitfor delay '0:0:2' --      0.000033\n",
      " drop table temp --                                                       0.000033\n",
      " grant resource to name                                                   0.000033\n",
      " /*Select all the columns of all the records in the Customers table:*/    0.000033\n",
      " EXEC SelectAllCustomers                                                  0.000033\n",
      "*/                                                                        0.000033\n",
      " CREATE VIEW [Products Above Average Price] AS                            0.000033\n",
      " CREATE OR REPLACE VIEW view_name AS                                      0.000033\n",
      " SELECT column_name ( s )                                                 0.000033\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Spalten ansehen\n",
    "print(sql_df.columns.tolist())\n",
    "\n",
    "# Typische Index-/Hilfsspalten loswerden\n",
    "sql_df = sql_df.loc[:, ~sql_df.columns.str.contains(r\"^Unnamed|^index$\", case=False)]\n",
    "\n",
    "# Auf die Kernspalten reduzieren (falls etwas anderes drin ist)\n",
    "sql_df = sql_df[[\"Sentence\", \"Label\"]].copy()\n",
    "\n",
    "# Optional: Duplikate auf Satzebene entfernen (falls noch nicht passiert)\n",
    "sql_df = sql_df.drop_duplicates(subset=[\"Sentence\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"clean shape:\", sql_df.shape)  # Erwartung: (30873, 2)\n",
    "print(sql_df[\"Label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce598302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (sql_df, xss_df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5eedf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xy(df: pd.DataFrame,\n",
    "                  label_candidates=(\"label\", \"class\", \"target\"),\n",
    "                  label_map=None):\n",
    "    if label_map is None:\n",
    "        label_map = {\n",
    "            \"0\": \"0\", \"1\": \"1\",\n",
    "            \"benign\": \"0\", \"normal\": \"0\", \"legitimate\": \"0\", \"safe\": \"0\",\n",
    "            \"attack\": \"1\", \"malicious\": \"1\", \"sql injection\": \"1\",\n",
    "            \"sql-injection\": \"1\", \"xss\": \"1\"\n",
    "        }\n",
    "\n",
    "    # Zielspalte finden (im *übergebenen* df!)\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    target_col = next((cols_lower[c] for c in label_candidates if c in cols_lower), None)\n",
    "    if target_col is None:\n",
    "        raise ValueError(f\"Keine Label-Spalte gefunden. Kandidaten: {label_candidates}\")\n",
    "\n",
    "    # Labels normieren -> nur 0/1 behalten\n",
    "    y_str = df[target_col].astype(str).str.strip().str.lower()\n",
    "    y_map = y_str.map(label_map)\n",
    "    mask = y_map.notna()\n",
    "    y = pd.to_numeric(y_map[mask]).astype(int).to_numpy()\n",
    "\n",
    "    # Rohtext aus allen Nicht-Label-Spalten zusammenbauen\n",
    "    feat_cols = [c for c in df.columns if c != target_col]\n",
    "    X_raw = df.loc[mask, feat_cols].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    return X_raw, y, target_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb270e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\", ngram_range=(3,5), min_df=2, max_features=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ebf89",
   "metadata": {},
   "source": [
    "## Splitting & Measure-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b3207c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    X = df[FEATURES].values\n",
    "    y = df[target_col].astype(int).values\n",
    "    return train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a217b",
   "metadata": {},
   "source": [
    "Erst den Datensatz splitten, um Data Leakage vorzubeugen, Wujek et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe1ac042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "\n",
    "    \"\"\"Evaluiert das Modell und gibt ein dic mit den Metriken zurück.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "    return dict(Model=name, Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d697d2",
   "metadata": {},
   "source": [
    "Dictionary für die Evaulierungsmetriken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fea7e",
   "metadata": {},
   "source": [
    "## Modeldefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b7d55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Parallelisierung der Modelle für bessere Laufzeit\\n\\n# scikit-learn / joblib\\nos.environ[\"OMP_NUM_THREADS\"] = \"8\"         # OpenMP\\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"    # NumPy / SciPy\\njoblib.parallel_backend(\"loky\", n_jobs=-1)  # überall -1 = alle Kerne\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Parallelisierung der Modelle für bessere Laufzeit\n",
    "\n",
    "# scikit-learn / joblib\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"         # OpenMP\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"    # NumPy / SciPy\n",
    "joblib.parallel_backend(\"loky\", n_jobs=-1)  # überall -1 = alle Kerne\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47f16504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxgb = XGBClassifier(\\n    tree_method=\"hist\",        # CPU-Optimierung\\n    n_estimators=400,\\n    max_depth=6,\\n    learning_rate=0.1,\\n    subsample=0.9,\\n    colsample_bytree=0.8,\\n    n_jobs=-1,\\n    random_state=42\\n)\\n\\nfrom catboost import CatBoostClassifier\\ncat = CatBoostClassifier(\\n    iterations=400,\\n    depth=8,\\n    learning_rate=0.1,\\n    random_seed=42,\\n    loss_function=\"Logloss\",\\n    task_type=\"CPU\",\\n    thread_count=8,\\n    od_type=\"Iter\",            # early stopping\\n    od_wait=30,\\n    verbose=False\\n)\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xgb = XGBClassifier(\n",
    "    tree_method=\"hist\",        # CPU-Optimierung\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=400,\n",
    "    depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=42,\n",
    "    loss_function=\"Logloss\",\n",
    "    task_type=\"CPU\",\n",
    "    thread_count=8,\n",
    "    od_type=\"Iter\",            # early stopping\n",
    "    od_wait=30,\n",
    "    verbose=False\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "407c50e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvec = TfidfVectorizer(\\n    ngram_range=(3,5),\\n    max_features=50_000,\\n    sublinear_tf=True,\\n    lowercase=False\\n).fit(X_train_raw)           # nur einmal fitten\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speicher optimieren\n",
    "'''\n",
    "vec = TfidfVectorizer(\n",
    "    ngram_range=(3,5),\n",
    "    max_features=50_000,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=False\n",
    ").fit(X_train_raw)           # nur einmal fitten\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9fb31025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsearch_space = {\\n    \"max_depth\": [4, 6, 8],\\n    \"learning_rate\": [0.05, 0.1, 0.2],\\n    \"n_estimators\": [200, 400, 600]\\n}\\nrandcv = RandomizedSearchCV(\\n    xgb,\\n    search_space,\\n    n_iter=10,            # statt 3×3×3 = 27\\n    scoring=\"f1\",\\n    cv=3,\\n    n_jobs=-1\\n)\\nrandcv.fit(X_train_vec, y_train)\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kleine Hyperparamsuche statt Grid-Overkill\n",
    "'''\n",
    "search_space = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [200, 400, 600]\n",
    "}\n",
    "randcv = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    search_space,\n",
    "    n_iter=10,            # statt 3×3×3 = 27\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "randcv.fit(X_train_vec, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3454871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\n",
    "#\"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "#\"MLP\": MLPClassifier(hidden_layer_sizes=(512, 256), activation=\"relu\", alpha= 1e-4, learning_rate_init=1e-3, early_stopping=True, random_state=RANDOM_STATE, max_iter=30),\n",
    "#\"XGBoost\": XGBClassifier(n_estimators=500, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "#\"CatBoost\": CatBoostClassifier(iterations=400, depth=8, learning_rate=0.1, loss_function=\"Logloss\", random_seed=RANDOM_STATE, verbose=False),\n",
    "\"TabPFN\": TabPFNClassifier(device=\"cpu\", ignore_pretraining_limits=True) # ingorieren der 500/10 000-Grenzen -> führt zu Absturz\n",
    "\n",
    "#-----GPU--------\n",
    "#\"MLP\": MLPClassifier(hidden_layer_sizes=(256, 128), activation=\"relu\", early_stopping=True, random_state=RANDOM_STATE, max_iter=50),\n",
    "#\"XGBoost\": XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, subsample=0.9, colsample_bytree=0.8, tree_method=\"hist\", device = \"cuda\", predictor=\"gpu_predictor\", random_state=RANDOM_STATE),\n",
    "#\"CatBoost\": CatBoostClassifier(iterations=500, depth=8, learning_rate=0.1, loss_function=\"Logloss\", task_type=\"GPU\", devices=\"0\", random_seed=RANDOM_STATE, verbose=False),\n",
    "#\"TabPFN\": TabPFNClassifier(device=\"cuda\", ignore_pretraining_limits=True) #erlaubt >10k Samples / >500 Features\n",
    "\n",
    "\n",
    "#'''XXXX---- \n",
    "#'''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8da7b",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dbc7080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "<class 'int'>    13686\n",
      "Name: count, dtype: int64\n",
      "1    7373\n",
      "0    6313\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_s = pd.Series(y)\n",
    "print(y_s.dtype)\n",
    "print(y_s.apply(type).value_counts().head())      # zeigt gemischte Typen\n",
    "print(y_s.value_counts(dropna=False).head(10))    # zeigt Labelwerte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "369ec28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for df, ds_name in [(sql_df, \"SQL\"), (xss_df, \"XSS\")]:\n",
    "    X_raw, y, target_col = preprocess_xy(df) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_raw,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed7ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gemeinsmaer TF-IDF-Vectorizer (fit nur auf Train, wegen Oversampling)\n",
    "vec = vectorizer.fit(X_train)\n",
    "X_train_vec = vec.transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283a1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def predict_in_batches(model, X, batch_size=512): #um Überlastung zu vermeiden, evtl. 256 oder 128\n",
    "    \"\"\"Make predictions on input data in batches.\"\"\"\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        batch = X[i:i + batch_size]\n",
    "        preds.append(model.predict(batch))\n",
    "    return np.concatenate(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabPFN] device=cpu\n",
      "[TabPFN] fit (8000, 200) in 6.9s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_in_batches(model, X, batch_size=128):\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        preds.append(model.predict(X[i:i+batch_size]))\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # ---------------------------------\n",
    "    # CatBoost\n",
    "    # ---------------------------------\n",
    "    if name == \"CatBoost\":\n",
    "        train_pool = Pool(X_train_vec, y_train)     # Sparse geht hier\n",
    "        model.fit(train_pool)\n",
    "        # CatBoost akzeptiert CSR im Predict:\n",
    "        res = evaluate_model(model, X_test_vec, y_test, f\"{name}-{ds_name}\")\n",
    "\n",
    "    # ---------------------------------\n",
    "    # TabPFN\n",
    "    # ---------------------------------\n",
    "    elif name == \"TabPFN\":\n",
    "        # Device + Limits (GPU falls verfügbar)\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        model.set_params(device=\"cuda\" if use_cuda else \"cpu\",\n",
    "                         ignore_pretraining_limits=True)\n",
    "        print(f\"[TabPFN] device={'cuda' if use_cuda else 'cpu'}\")\n",
    "\n",
    "        # ggf. stratifiziert auf 8k reduzieren (Zeit/RAM)\n",
    "        MAX_SAMPLES = 8_000\n",
    "        X_train_tab, y_train_tab = X_train_vec, y_train\n",
    "        if X_train_vec.shape[0] > MAX_SAMPLES:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=MAX_SAMPLES,\n",
    "                                         random_state=RANDOM_STATE)\n",
    "            train_idx, _ = next(sss.split(X_train_vec, y_train))\n",
    "            X_train_tab = X_train_vec[train_idx]\n",
    "            y_train_tab = np.asarray(y_train)[train_idx]\n",
    "\n",
    "        # TF-IDF -> SVD (<=500 Features), float32 spart RAM\n",
    "        svd = TruncatedSVD(n_components=200, random_state=RANDOM_STATE)\n",
    "        X_train_svd = svd.fit_transform(X_train_tab).astype(\"float32\", copy=False)\n",
    "        X_test_svd  = svd.transform(X_test_vec).astype(\"float32\", copy=False)\n",
    "\n",
    "        # Fit\n",
    "        t0 = time.time()\n",
    "        model.fit(X_train_svd, y_train_tab)\n",
    "        print(f\"[TabPFN] fit {X_train_svd.shape} in {time.time()-t0:.1f}s\")\n",
    "\n",
    "        # Batched Predict (keine zweite Prediction durch evaluate_model!)\n",
    "        y_pred = predict_in_batches(model, X_test_svd, batch_size=128)\n",
    "\n",
    "        # Metriken inline (identisch zu evaluate_model)\n",
    "        p  = precision_score(y_test, y_pred)\n",
    "        r  = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        fpr = float(fp / (fp + tn))\n",
    "        fnr = float(fn / (fn + tp))\n",
    "        res = dict(Model=f\"{name}-{ds_name}\", Precision=p, Recall=r, F1=f1, FPR=fpr, FNR=fnr)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # Alle anderen Modelle\n",
    "    # ---------------------------------\n",
    "    else:\n",
    "        X_tr, X_te = X_train_vec, X_test_vec\n",
    "        model.fit(X_tr, y_train)\n",
    "        res = evaluate_model(model, X_te, y_test, f\"{name}-{ds_name}\")\n",
    "\n",
    "    results.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4caea88",
   "metadata": {},
   "source": [
    "## Ergebnistabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd-DataFrame(results)\n",
    "results_df.sort_values([\"Model\"], inplace=True)\n",
    "print(\"\\n Gesamt Ergebnisse: \\n\", results_df)\n",
    "\n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4015df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Variante A – wenn df_results bereits eine 'Dataset'-Spalte hat\n",
    "if \"Dataset\" in df_results.columns:\n",
    "    df_sql = df_results[df_results[\"Dataset\"] == \"SQL\"].copy()\n",
    "    df_xss = df_results[df_results[\"Dataset\"] == \"XSS\"].copy()\n",
    "# Variante B – Spalte fehlt -> am Modell-Namen aufteilen\n",
    "else:\n",
    "    df_sql = df_results[df_results[\"Model\"].str.contains(\"-SQL\")].copy()\n",
    "    df_xss = df_results[df_results[\"Model\"].str.contains(\"-XSS\")].copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) zwei CSV-Dateien \n",
    "# ------------------------------------------------------------\n",
    "df_sql.to_csv(\"results_sql.csv\", index=False, sep=\";\")\n",
    "df_xss.to_csv(\"results_xss.csv\", index=False, sep=\";\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Excel-Workbook mit zwei Sheets\n",
    "# ------------------------------------------------------------\n",
    "with pd.ExcelWriter(\"results_by_dataset.xlsx\") as writer:\n",
    "    df_sql.to_excel(writer, sheet_name=\"SQL\", index=False)\n",
    "    df_xss.to_excel(writer, sheet_name=\"XSS\", index=False)\n",
    "\n",
    "print( \"Dateien wurden exportiert: results_sql.csv, results_xss.csv, results_by_dataset.xlsx\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c2ae6",
   "metadata": {},
   "source": [
    "## Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd3b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd036337",
   "metadata": {},
   "source": [
    "## K-Fold-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae0362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
